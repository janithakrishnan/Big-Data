{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download 5 dataset from any of the following and perform operations using pandas\n",
    "# https://people.sc.fsu.edu/~jburkardt/data/csv/csv.html\n",
    "# https://github.com/datablist/sample-csv-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "addresses.csv\n",
      "                        0         1                                 2  \\\n",
      "0                   John       Doe                 120 jefferson st.   \n",
      "1                   Jack  McGinnis                      220 hobo Av.   \n",
      "2          John \"Da Man\"    Repici                 120 Jefferson St.   \n",
      "3                Stephen     Tyler  7452 Terrace \"At the Plaza\" road   \n",
      "4                    NaN  Blankman                               NaN   \n",
      "5  Joan \"the bone\", Anne       Jet               9th, at Terrace plc   \n",
      "\n",
      "             3    4      5  \n",
      "0    Riverside   NJ   8075  \n",
      "1        Phila   PA   9119  \n",
      "2    Riverside   NJ   8075  \n",
      "3     SomeTown   SD  91234  \n",
      "4     SomeTown   SD    298  \n",
      "5  Desert City   CO    123  \n",
      "\n",
      "airtravel.csv\n",
      "    Month   \"1958\"   \"1959\"   \"1960\"\n",
      "0    JAN      340      360      417\n",
      "1    FEB      318      342      391\n",
      "2    MAR      362      406      419\n",
      "3    APR      348      396      461\n",
      "4    MAY      363      420      472\n",
      "5    JUN      435      472      535\n",
      "6    JUL      491      548      622\n",
      "7    AUG      505      559      606\n",
      "8    SEP      404      463      508\n",
      "9    OCT      359      407      461\n",
      "10   NOV      310      362      390\n",
      "11   DEC      337      405      432\n",
      "\n",
      "biostats.csv\n",
      "     Name       \"Sex\"   \"Age\"   \"Height (in)\"   \"Weight (lbs)\"\n",
      "0   Alex         \"M\"      41              74              170\n",
      "1   Bert         \"M\"      42              68              166\n",
      "2   Carl         \"M\"      32              70              155\n",
      "3   Dave         \"M\"      39              72              167\n",
      "4   Elly         \"F\"      30              66              124\n",
      "5   Fran         \"F\"      33              66              115\n",
      "6   Gwen         \"F\"      26              64              121\n",
      "7   Hank         \"M\"      30              71              158\n",
      "8   Ivan         \"M\"      53              72              175\n",
      "9   Jake         \"M\"      32              69              143\n",
      "10  Kate         \"F\"      47              69              139\n",
      "11  Luke         \"M\"      34              72              163\n",
      "12  Myra         \"F\"      23              62               98\n",
      "13  Neil         \"M\"      36              75              160\n",
      "14  Omar         \"M\"      38              70              145\n",
      "15  Page         \"F\"      31              67              135\n",
      "16  Quin         \"M\"      29              71              176\n",
      "17  Ruth         \"F\"      28              65              131\n",
      "\n",
      "cities.csv\n",
      "      LatD   \"LatM\"   \"LatS\"  \"NS\"   \"LonD\"   \"LonM\"   \"LonS\"  \"EW\"  \\\n",
      "0      41        5       59   \"N\"       80       39        0   \"W\"   \n",
      "1      42       52       48   \"N\"       97       23       23   \"W\"   \n",
      "2      46       35       59   \"N\"      120       30       36   \"W\"   \n",
      "3      42       16       12   \"N\"       71       48        0   \"W\"   \n",
      "4      43       37       48   \"N\"       89       46       11   \"W\"   \n",
      "..    ...      ...      ...   ...      ...      ...      ...   ...   \n",
      "123    39       31       12   \"N\"      119       48       35   \"W\"   \n",
      "124    50       25       11   \"N\"      104       39        0   \"W\"   \n",
      "125    40       10       48   \"N\"      122       14       23   \"W\"   \n",
      "126    40       19       48   \"N\"       75       55       48   \"W\"   \n",
      "127    41        9       35   \"N\"       81       14       23   \"W\"   \n",
      "\n",
      "                 \"City\"  \"State\"  \n",
      "0          \"Youngstown\"       OH  \n",
      "1             \"Yankton\"       SD  \n",
      "2              \"Yakima\"       WA  \n",
      "3           \"Worcester\"       MA  \n",
      "4     \"Wisconsin Dells\"       WI  \n",
      "..                  ...      ...  \n",
      "123              \"Reno\"       NV  \n",
      "124            \"Regina\"       SA  \n",
      "125         \"Red Bluff\"       CA  \n",
      "126           \"Reading\"       PA  \n",
      "127           \"Ravenna\"      OH   \n",
      "\n",
      "[128 rows x 10 columns]\n",
      "\n",
      "crash_catalonia.csv\n",
      "   Day of Week   \"Number of Crashes\"\n",
      "0      Sunday                 13664\n",
      "1      Monday                 17279\n",
      "2     Tuesday                 17337\n",
      "3   Wednesday                 17394\n",
      "4    Thursday                 17954\n",
      "5      Friday                 19147\n",
      "6    Saturday                 15714\n"
     ]
    }
   ],
   "source": [
    "# Use pandas and read csv files into dataframe\n",
    "import pandas as pd\n",
    "df1=pd.read_csv('/home/sw900b4_janitha/Assignments Janitha/big_data/code/Data_June4/addresses.csv',header=None)\n",
    "print('\\naddresses.csv\\n',df1)\n",
    "df2=pd.read_csv('/home/sw900b4_janitha/Assignments Janitha/big_data/code/Data_June4/airtravel.csv',header=0)\n",
    "print('\\nairtravel.csv\\n',df2)\n",
    "df3=pd.read_csv('/home/sw900b4_janitha/Assignments Janitha/big_data/code/Data_June4/biostats.csv',header=0)\n",
    "print('\\nbiostats.csv\\n',df3)\n",
    "df4=pd.read_csv('/home/sw900b4_janitha/Assignments Janitha/big_data/code/Data_June4/cities.csv',header=0)\n",
    "print('\\ncities.csv\\n',df4)\n",
    "df5=pd.read_csv('/home/sw900b4_janitha/Assignments Janitha/big_data/code/Data_June4/crash_catalonia.csv',header=0)\n",
    "print('\\ncrash_catalonia.csv\\n',df5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00717ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
